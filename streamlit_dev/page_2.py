# chat.py
import streamlit as st
import os
import textwrap
from io import StringIO
from google import genai
from google.genai.types import GenerateContentConfig
from api.sysp import system_prompt
import base64


# Ensure the API key is set via secrets.toml or environment variable
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY") or st.secrets["GEMINI_API_KEY"]
MODEL_NAME = 'gemini-2.5-flash'
ss = st.session_state

# Retrieve quiz data from Session State (set by the quiz page)
final_score = ss.get('final_quiz_score')
total_questions = ss.get('quiz_total_questions')
failed_questions = ss.get('failed_questions')
highest_score = ss.get('highest_score')

def get_base64_of_bin_file(bin_file):
    """ Reads a binary file and returns its Base64 encoded string. """
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()

try:
    user_avatar_path = "generic_headshot.png"
    bot_avatar_path = "headshot.png"
    user_avatar = f"data:image/png;base64,{get_base64_of_bin_file(user_avatar_path)}"
    bot_avatar = f"data:image/png;base64,{get_base64_of_bin_file(bot_avatar_path)}"
except FileNotFoundError:
    # Use default emojis if images are not found
    user_avatar = "游녻"
    bot_avatar = "游뱄"
    st.warning("Avatar images not found. Using default emojis. Please add 'user_avatar.png' and 'bot_avatar.png'.")




# --- Gemini Client Initialization and System Prompt ---
if "client" not in ss:
    try:
        ss.client = genai.Client(api_key=GEMINI_API_KEY)
    except Exception as e:
        st.error(f"Error initializing Gemini client: {e}")
        st.stop()
        
def build_system_prompt():
    """Builds the comprehensive system prompt including quiz data."""
    
    # 1. Base Persona (Harald the Swedish Tutor)
    prompt = textwrap.dedent(system_prompt)
    
    # 2. Quiz Performance Context
    if final_score is not None and total_questions is not None:
        
        score_percentage = (final_score / total_questions) * 100
        prompt += f"\nAnv칛ndaren har nyligen genomf칬rt ett ordf칬rr친dsquiz och fick {final_score} av {total_questions} ({score_percentage:.0f}%)."
        
        if highest_score is not None and highest_score > 0:
            prompt += f"Anv칛ndarens b칛sta resultat hittills 칛r {highest_score} av {total_questions}."

        # 3. Failed Questions for Targeted Help
        if failed_questions and len(failed_questions) > 0:
            failed_q_summary = StringIO()
            failed_q_summary.write("Anv칛ndaren hade problem med f칬ljande ord/fr친gor:\n")
            for i, q in enumerate(failed_questions):
                failed_q_summary.write(f"  - Fr친ga: '{q.get('question')}' (Korrekt svar: {q.get('correct')}).\n")
            
            prompt += "\nBer칛tta f칬r anv칛ndaren att du sett att den gjort en quiz och f칬resl친 att hj칛lpa med de fr친gor anv칛ndaren haft fel p친! Viktigt!"
            prompt += failed_q_summary.getvalue()
        else:
            prompt += "\nAnv칛ndaren klarade alla fr친gor! Fokusera p친 att bygga vidare p친 deras kunskap."
    else:
        prompt += "\nAnv칛ndaren har inte genomf칬rt quizet 칛nnu. Fokusera p친 allm칛n konversation och uppmuntra dem att ta quizet."
        
    return prompt.strip()

# --- Chat Initialization ---

if "messages" not in ss:
    # Build the system context at startup
    system_prompt_text = build_system_prompt()
    ss.messages = [] 
    ss.system_prompt = system_prompt_text

    # Add the initial Harald greeting
    initial_greeting = "Hall친! Jag heter Harald, din personliga svenskl칛rare. Hur kan jag hj칛lpa dig idag?"
    ss.messages.append({"role": "harald", "content": initial_greeting})

if "chat_session" not in ss:
    # Initialize the configuration with the stored system prompt
    config = GenerateContentConfig(
        system_instruction=ss.system_prompt,
        # You can add safety_settings here if you want:
        # safety_settings=...
    )
    
    # Initialize the chat session
    ss.chat_session = ss.client.chats.create(
        model=MODEL_NAME,
        config=config, 
        # Convert Streamlit history format to Gemini API format
        history=[
            {"role": "model" if msg["role"] == "harald" else "user", 
             "parts": [{"text": msg["content"]}]} 
            for msg in ss.messages
        ]
    )


# --- CSS (Remains the same) ---
st.markdown(
    # ... (Your CSS style block) ...
    """
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Kanchenjunga:wght@400;500;600;700&family=Libre+Baskerville:wght@700&display=swap');

    .big-text {
        font-family: 'Libre Baskerville', serif;
        font-size: 100px;
        font-weight: 700;
        color: rgba(0,0,0,0.5); /* make it light so chat is readable */
        position: fixed;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        z-index: -1;  /* behind everything */
        pointer-events: none;  /* click through */
        user-select: none;      /* prevent selection */
        text-align: center;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# --- Display History ---
for message in ss.messages:
    role = message["role"]
    avatar = bot_avatar if role == "harald" else user_avatar
    display_role = "assistant" if role == "harald" else role
    with st.chat_message(display_role, avatar=avatar):
        st.markdown(message["content"])

# --- Chat Input and Response Logic (Non-streaming) ---
if prompt := st.chat_input("Vad vill du fr친ga Harald?"):
    
    # 1. Display user message and append to history
    st.chat_message("user", avatar=user_avatar).markdown(prompt)
    ss.messages.append({"role": "user", "content": prompt})
    
    try:
        with st.spinner("..."):
            response = ss.chat_session.send_message(prompt)
            
            # Get the text content
            full_response = response.text
    except Exception as e:
        full_response = f"Jag ber om urs칛kt, ett fel uppstod vid kommunikationen: {e}"
        st.error(full_response)


    # 3. Display the full response from Harald
    with st.chat_message("assistant", avatar=bot_avatar):
        st.markdown(full_response)

    # 4. Add the model's final response to history
    ss.messages.append({"role": "harald", "content": full_response})